{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NS8SEuoNOks8"
   },
   "outputs": [],
   "source": [
    "pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8SwF6wabOb7x"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from collections import Counter\n",
    "#from konlpy.tag import Mecab\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0mOmHi0QIbI"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('total_final_새로운별점_0제거.csv',usecols=['review','star','new_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QHlJ2Yx_TOJg"
   },
   "outputs": [],
   "source": [
    "data['review'].nunique(),data['star'].nunique(),data['new_label'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_pMBxF1jTcQx"
   },
   "outputs": [],
   "source": [
    "# 중복 리뷰 제거\n",
    "data.drop_duplicates(subset=['review'], inplace=True) # reviews 열에서 중복인 내용이 있다면 중복 제거\n",
    "print('총 샘플의 수 :',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YaXPGdPyTi9d"
   },
   "outputs": [],
   "source": [
    "\n",
    "# null 값 확인\n",
    "print(data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpINO8XyTqwn"
   },
   "outputs": [],
   "source": [
    "# 데이터 분리\n",
    "train_data, test_data = train_test_split(data, test_size = 0.25, random_state = 38)\n",
    "print('훈련용 리뷰의 개수 :', len(train_data))\n",
    "print('테스트용 리뷰의 개수 :', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-Yx03PFTxky"
   },
   "outputs": [],
   "source": [
    "train_data['new_label'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QsTEiuk5UCyX"
   },
   "outputs": [],
   "source": [
    "print(train_data.groupby('new_label').size().reset_index(name = 'count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFTMWN-DUGyO"
   },
   "outputs": [],
   "source": [
    "train_data['review'] = train_data['review'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data['review'].replace('', np.nan, inplace=True)\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_hG3TzxUMDm"
   },
   "outputs": [],
   "source": [
    "test_data.drop_duplicates(subset = ['review'], inplace=True) # 중복 제거\n",
    "test_data['review'] = test_data['review'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
    "test_data['review'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n",
    "test_data = test_data.dropna(how='any') # Null 값 제거\n",
    "print('전처리 후 테스트용 샘플의 개수 :',len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txB0j6_5Udww"
   },
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "print(okt.morphs('와 이런 것도 상품이라고 차라리 내가 만드는 게 나을 뻔',stem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0e0BXBbVjnu"
   },
   "outputs": [],
   "source": [
    "f = open(\"불용어사전.txt\", 'r')\n",
    "line = f.readlines()\n",
    "bul = []\n",
    "for word in line:\n",
    "    word = word.replace('\\n','')\n",
    "    bul.append(word)\n",
    "\n",
    "print(bul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cXB1v7vZWESO"
   },
   "outputs": [],
   "source": [
    "train_data['tokenized'] = train_data['review'].apply(okt.morphs,)\n",
    "train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [item for item in x if item not in bul])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6LZxYFrWzwg"
   },
   "outputs": [],
   "source": [
    "test_data['tokenized'] = test_data['review'].apply(okt.morphs)\n",
    "test_data['tokenized'] = test_data['tokenized'].apply(lambda x: [item for item in x if item not in bul])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "meWVVWu8W4cy"
   },
   "outputs": [],
   "source": [
    "negative_words = np.hstack(train_data[train_data.new_label == 0]['tokenized'].values)\n",
    "positive_words = np.hstack(train_data[train_data.new_label == 1]['tokenized'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GybsVNqWW5KW"
   },
   "outputs": [],
   "source": [
    "negative_word_count = Counter(negative_words)\n",
    "print(negative_word_count.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQkqA2GoXGoX"
   },
   "outputs": [],
   "source": [
    "positive_word_count = Counter(positive_words)\n",
    "print(positive_word_count.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyCJR7GHXMEA"
   },
   "outputs": [],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n",
    "text_len = train_data[train_data['new_label']==1]['tokenized'].map(lambda x: len(x))\n",
    "ax1.hist(text_len, color='red')\n",
    "ax1.set_title('Positive Reviews')\n",
    "ax1.set_xlabel('length of samples')\n",
    "ax1.set_ylabel('number of samples')\n",
    "print('긍정 리뷰의 평균 길이 :', np.mean(text_len))\n",
    "\n",
    "text_len = train_data[train_data['new_label']==0]['tokenized'].map(lambda x: len(x))\n",
    "ax2.hist(text_len, color='blue')\n",
    "ax2.set_title('Negative Reviews')\n",
    "fig.suptitle('Words in texts')\n",
    "ax2.set_xlabel('length of samples')\n",
    "ax2.set_ylabel('number of samples')\n",
    "print('부정 리뷰의 평균 길이 :', np.mean(text_len))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-xgFlfmXOb0"
   },
   "outputs": [],
   "source": [
    "X_train = train_data['tokenized'].values\n",
    "y_train = train_data['new_label'].values\n",
    "X_test= test_data['tokenized'].values\n",
    "y_test = test_data['new_label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UMcd1ZyxXXry"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCflUeQ6XcD5"
   },
   "outputs": [],
   "source": [
    "threshold = 2\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yG0Ls6WmXmy-"
   },
   "outputs": [],
   "source": [
    "# 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거.\n",
    "# 0번 패딩 토큰과 1번 OOV 토큰을 고려하여 +2\n",
    "vocab_size = total_cnt - rare_cnt + 2\n",
    "print('단어 집합의 크기 :',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68O-ljQtXb-L"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size, oov_token = 'OOV') \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lEJN4J6SXb3b"
   },
   "outputs": [],
   "source": [
    "#패딩\n",
    "print('리뷰의 최대 길이 :',max(len(review) for review in X_train))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
    "plt.hist([len(review) for review in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5fjtoclXXtQ0"
   },
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  count = 0\n",
    "  for sentence in nested_list:\n",
    "    if(len(sentence) <= max_len):\n",
    "        count = count + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UYRYKSHZXtMa"
   },
   "outputs": [],
   "source": [
    "max_len = 95\n",
    "below_threshold_len(max_len, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ETK_im_yXtHg"
   },
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7NxIRYMYFMh"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(GRU(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wdSWTqCbYFBn"
   },
   "outputs": [],
   "source": [
    "loaded_model = load_model('best_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ljpQDQyYE8_"
   },
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "  new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
    "  new_sentence = okt.morphs(new_sentence)\n",
    "  new_sentence = [word for word in new_sentence if not word in bul]\n",
    "  encoded = tokenizer.texts_to_sequences([new_sentence])\n",
    "  pad_new = pad_sequences(encoded, maxlen = max_len)\n",
    "\n",
    "  score = float(loaded_model.predict(pad_new))\n",
    "  if(score > 0.5):\n",
    "    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\".format(score * 100))\n",
    "  else:\n",
    "    print(\"{:.2f}% 확률로 부정 리뷰입니다.\".format((1 - score) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qyMKCWBHYE2D"
   },
   "outputs": [],
   "source": [
    "sentiment_predict('침대는 좋지만 의자가 너무 낮아요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTo0XeYyYwkz"
   },
   "outputs": [],
   "source": [
    "sentiment_predict('매트리스가 약간단단하네요. 잘사용할게요.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSLdJR8rY58j"
   },
   "outputs": [],
   "source": [
    "sentiment_predict('생각보다 푹신하네요 전 조금 더 딱딱한걸 선호했는데')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9D4XHiMZLy1"
   },
   "outputs": [],
   "source": [
    "sentiment_predict('제가 출근해서 문옆에 두라고 했는데 2층계단으로 혼자 운반하기 버거웠나봐요 모서리가 비닐포장지랑같이 파손되었네요ㅠ 박스포장이 아니라 좀.. 반품하려다 배송도 느린데 또 기다리가가 지겨워서 그냥 사용하려구요 이런부분은 신경 써 주시면 좋겠어요')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gru_test_0426.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
