{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bc95ef3-0f9a-4464-8e63-c28cf0c5aeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from scipy import stats\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a61ff5a7-584a-42f4-a5e9-bd7364df7426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separator(text):\n",
    "    return re.sub(pattern=\"<b.*/>|\\.|\\?|\\!\", string=text, repl=\" [SEP] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b2803c-e001-4623-b6e8-2a8bbd92d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b9a0b3-6df4-4c31-b7d3-81fd55a86cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.4.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ae691a-e03a-4174-8e87-7a42ef3b5660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a44b9cfa-17d4-4cb5-bbcf-140055f8463c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21034721-5221-42b7-810a-558653188e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.2+cu102'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9b8d2e5-0167-44d6-9ece-8d97a90def40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddbc7421-fa15-4024-8ee7-e04b4ebdffa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>reviews</th>\n",
       "      <th>label</th>\n",
       "      <th>new_label</th>\n",
       "      <th>new_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>﻿좋다 가격 구매 수납 공간 조금 많이 작다 정도 그냥 없다 모델 살 걸 그렇다 라...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>침대 프레임 정말 실망 기존 싸다 제품 비교 상품 설명 보고 수납 달리 홀 뚫리다 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>별로 사진 처럼 침대 하단 부 시트 지 가다 조금 벗겨지다 기사 설치 그렇다 건 지...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>설치 기사 가다 프레임 헤드 쪽 깨다 못 보신 건지다 말씀 안 해주다 속상하다 누우...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>월일 설치 달 사용 서랍 장이 분리 버리다 서랍 장이 톱밥 뭉치다 합판 너무 약하다...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21304</th>\n",
       "      <td>21304</td>\n",
       "      <td>폭 아쉽다 기다 하지만 튼튼하다 분위기</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21305</th>\n",
       "      <td>21305</td>\n",
       "      <td>사용 좋다</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21306</th>\n",
       "      <td>21306</td>\n",
       "      <td>튼튼하다 수납 공간 좋다 여전하다 만족하다</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21307</th>\n",
       "      <td>21307</td>\n",
       "      <td>지방 보다 배송 늦다 기사 바쁘다 그냥 집 두다 가시 보다 균형 잡다 애 먹다 후 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21308</th>\n",
       "      <td>21308</td>\n",
       "      <td>앉다 오래 일해 서 허리 아프다 구매 설치 시간 정도 정리 같다 너무 너무 맘 들다...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21309 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1                                            reviews  label  \\\n",
       "0                 0  ﻿좋다 가격 구매 수납 공간 조금 많이 작다 정도 그냥 없다 모델 살 걸 그렇다 라...      0   \n",
       "1                 1  침대 프레임 정말 실망 기존 싸다 제품 비교 상품 설명 보고 수납 달리 홀 뚫리다 ...      0   \n",
       "2                 2  별로 사진 처럼 침대 하단 부 시트 지 가다 조금 벗겨지다 기사 설치 그렇다 건 지...      0   \n",
       "3                 3  설치 기사 가다 프레임 헤드 쪽 깨다 못 보신 건지다 말씀 안 해주다 속상하다 누우...      0   \n",
       "4                 4  월일 설치 달 사용 서랍 장이 분리 버리다 서랍 장이 톱밥 뭉치다 합판 너무 약하다...      0   \n",
       "...             ...                                                ...    ...   \n",
       "21304         21304                              폭 아쉽다 기다 하지만 튼튼하다 분위기      1   \n",
       "21305         21305                                              사용 좋다      1   \n",
       "21306         21306                            튼튼하다 수납 공간 좋다 여전하다 만족하다      1   \n",
       "21307         21307  지방 보다 배송 늦다 기사 바쁘다 그냥 집 두다 가시 보다 균형 잡다 애 먹다 후 ...      1   \n",
       "21308         21308  앉다 오래 일해 서 허리 아프다 구매 설치 시간 정도 정리 같다 너무 너무 맘 들다...      1   \n",
       "\n",
       "       new_label  new_star  \n",
       "0              0         1  \n",
       "1              0         3  \n",
       "2              0         1  \n",
       "3              0         1  \n",
       "4              0         1  \n",
       "...          ...       ...  \n",
       "21304          0         4  \n",
       "21305          0         3  \n",
       "21306          0         5  \n",
       "21307          0         2  \n",
       "21308          0         1  \n",
       "\n",
       "[21309 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('total_final_cnn_0502.csv', encoding = 'utf-8', index_col = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c16878f-6d64-4361-b3a2-f9bceb7105de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>new_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿좋다 가격 구매 수납 공간 조금 많이 작다 정도 그냥 없다 모델 살 걸 그렇다 라...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>침대 프레임 정말 실망 기존 싸다 제품 비교 상품 설명 보고 수납 달리 홀 뚫리다 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>별로 사진 처럼 침대 하단 부 시트 지 가다 조금 벗겨지다 기사 설치 그렇다 건 지...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>설치 기사 가다 프레임 헤드 쪽 깨다 못 보신 건지다 말씀 안 해주다 속상하다 누우...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>월일 설치 달 사용 서랍 장이 분리 버리다 서랍 장이 톱밥 뭉치다 합판 너무 약하다...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21304</th>\n",
       "      <td>폭 아쉽다 기다 하지만 튼튼하다 분위기</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21305</th>\n",
       "      <td>사용 좋다</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21306</th>\n",
       "      <td>튼튼하다 수납 공간 좋다 여전하다 만족하다</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21307</th>\n",
       "      <td>지방 보다 배송 늦다 기사 바쁘다 그냥 집 두다 가시 보다 균형 잡다 애 먹다 후 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21308</th>\n",
       "      <td>앉다 오래 일해 서 허리 아프다 구매 설치 시간 정도 정리 같다 너무 너무 맘 들다...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21309 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews  new_star\n",
       "0      ﻿좋다 가격 구매 수납 공간 조금 많이 작다 정도 그냥 없다 모델 살 걸 그렇다 라...         1\n",
       "1      침대 프레임 정말 실망 기존 싸다 제품 비교 상품 설명 보고 수납 달리 홀 뚫리다 ...         3\n",
       "2      별로 사진 처럼 침대 하단 부 시트 지 가다 조금 벗겨지다 기사 설치 그렇다 건 지...         1\n",
       "3      설치 기사 가다 프레임 헤드 쪽 깨다 못 보신 건지다 말씀 안 해주다 속상하다 누우...         1\n",
       "4      월일 설치 달 사용 서랍 장이 분리 버리다 서랍 장이 톱밥 뭉치다 합판 너무 약하다...         1\n",
       "...                                                  ...       ...\n",
       "21304                              폭 아쉽다 기다 하지만 튼튼하다 분위기         4\n",
       "21305                                              사용 좋다         3\n",
       "21306                            튼튼하다 수납 공간 좋다 여전하다 만족하다         5\n",
       "21307  지방 보다 배송 늦다 기사 바쁘다 그냥 집 두다 가시 보다 균형 잡다 애 먹다 후 ...         2\n",
       "21308  앉다 오래 일해 서 허리 아프다 구매 설치 시간 정도 정리 같다 너무 너무 맘 들다...         1\n",
       "\n",
       "[21309 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['reviews', 'new_star']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93be2c60-6f57-49d9-b4c6-d13b2df321a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = df.reviews\n",
    "classes = df.new_star\n",
    "classes_oh = classes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31ed0ae4-81aa-4c19-b6a8-a6c748caf928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tokenize(texts):\n",
    "    return [tokenizer.tokenize(\"[CLS] \" + text + \" [SEP]\") for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0731a8ce-9cc5-4e43-b8ed-880947b18bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('klue/bert-base', do_lower_case=False)\n",
    "tokenized = bert_tokenize(train_texts)\n",
    "bert_ids = [tokenizer.convert_tokens_to_ids(tokens) for tokens in tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb649885-bd80-407f-9653-7d5c8e58c6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=21309, minmax=(3, 124), mean=27.42165282275095, variance=465.00809317568905, skewness=1.451969884288213, kurtosis=1.6958084056781564)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_tokens = np.array([len(bert_id) for bert_id in bert_ids])\n",
    "stats.describe(number_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b13711c8-b4c6-429d-a529-3e3ccb076e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    2,  1560,  2062,  3852,  4625, 14272,  4101,  4027,  3732,\n",
       "        1518,  2062,  3681,  4181,  1415,  2062,  4347,  1236,   572,\n",
       "        3649,  2062,  9932,  1176,  4137,  5857,   572,  1381,  3788,\n",
       "        1258,   543,  2062,  1415,  2062,  3959,  8427,  4530,  1381,\n",
       "        2062, 20852,  4229,  6145,  2223,  2062,  9996,  1156,  9488,\n",
       "        4198,  2062,  4828,  1521,  1897,  2223,  2062,  5037,  2062,\n",
       "        3641,  3760,  4517,  6179,  2062,  4198,  2062,  1122,  2062,\n",
       "           3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = 300\n",
    "padded_bert_ids = pad_sequences(bert_ids, maxlen=MAX_LEN, dtype='long',\n",
    "\t\t\t\t\t\t\t\t\ttruncating='post', padding='post')\n",
    "padded_bert_ids[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb6cd08f-2ae3-40e0-a3ce-5b5db022a0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21309"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_masks = []\n",
    "for seq in padded_bert_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "len(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bd7963b-8e84-443b-af4d-a685164ca453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train: (15342, 300)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'X_val: (1705, 300)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'X_test: (4262, 300)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'y_train: (15342,)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'y_val: (1705,)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'y_test: (4262,)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'masks_train: 15342'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'masks_val: 1705'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'masks_test: 4262'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_bert_ids, classes_oh, random_state=42, test_size=0.2)\n",
    "\n",
    "masks_train, masks_test, _, _ = train_test_split(attention_masks, padded_bert_ids, \n",
    "                                                 random_state=42, test_size=0.2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42, test_size=0.1)\n",
    "\n",
    "masks_train, masks_val, _, _ = train_test_split(masks_train, masks_train, \n",
    "                                                 random_state=42, test_size=0.1)\n",
    "display(\n",
    "    f\"X_train: {X_train.shape}\",\n",
    "    f\"X_val: {X_val.shape}\",\n",
    "    f\"X_test: {X_test.shape}\",\n",
    "    f\"y_train: {y_train.shape}\",\n",
    "    f\"y_val: {y_val.shape}\",\n",
    "    f\"y_test: {y_test.shape}\",\n",
    "    f\"masks_train: {len(masks_train)}\",\n",
    "    f\"masks_val: {len(masks_val)}\",\n",
    "    f\"masks_test: {len(masks_test)}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d73fc72-4507-44bb-b5f2-80431d61486c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15342, 300])\n",
      "torch.Size([15342])\n",
      "torch.Size([15342, 300])\n",
      "torch.Size([1705, 300])\n",
      "torch.Size([1705])\n",
      "torch.Size([1705, 300])\n",
      "torch.Size([4262, 300])\n",
      "torch.Size([4262])\n",
      "torch.Size([4262, 300])\n"
     ]
    }
   ],
   "source": [
    "train_inputs = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "train_masks = torch.tensor(masks_train)\n",
    "validation_inputs = torch.tensor(X_val)\n",
    "validation_labels = torch.tensor(y_val)\n",
    "validation_masks = torch.tensor(masks_val)\n",
    "\n",
    "test_inputs = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "test_masks = torch.tensor(masks_test)\n",
    "\n",
    "print(train_inputs.shape)\n",
    "print(train_labels.shape)\n",
    "print(train_masks.shape)\n",
    "print(validation_inputs.shape)\n",
    "print(validation_labels.shape)\n",
    "print(validation_masks.shape)\n",
    "print(test_inputs.shape)\n",
    "print(test_labels.shape)\n",
    "print(test_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8974a19-56b9-4c46-bd61-2282b788a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "563ab767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_warning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73f10404-fcf7-4cb0-b99d-2e6fac8d2463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=5)\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # 학습률\n",
    "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
    "                )\n",
    "\n",
    "epochs = 4\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a533bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01681ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcf90949-c821-477e-b278-55e51140ddd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd0096c5-934c-40fc-a29b-4d32942fb747",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m b_input_ids, b_input_mask, b_labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Forward 수행                \u001b[39;00m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# 로스 구함\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# 총 로스 계산\u001b[39;00m\n\u001b[1;32m     70\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "# 정확도 계산 함수\n",
    "def flat_accuracy(preds, labels):\n",
    "    \n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "    \n",
    "\n",
    "# 재현을 위해 랜덤시드 고정\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# 그래디언트 초기화\n",
    "model.zero_grad()\n",
    "\n",
    "# 에폭만큼 반복\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # 시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 로스 초기화\n",
    "    total_loss = 0\n",
    "\n",
    "    # 훈련모드로 변경\n",
    "    model.train()\n",
    "        \n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # 경과 정보 표시\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Forward 수행                \n",
    "\n",
    "        \n",
    "        \n",
    "        # 로스 구함\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # 총 로스 계산\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward 수행으로 그래디언트 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 스케줄러로 학습률 감소\n",
    "        scheduler.step()\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        model.zero_grad()\n",
    "\n",
    "    # 평균 로스 계산\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    #시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 변수 초기화\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for batch in validation_dataloader:\n",
    "#         # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # 그래디언트 계산 안함\n",
    "        with torch.no_grad():     \n",
    "            # Forward 수행\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # 로스 구함\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # CPU로 데이터 이동\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"  Accuracy: {0:.4f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fa7dadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    996.    Elapsed: 0:00:07.\n",
      "  Batch   200  of    996.    Elapsed: 0:00:14.\n",
      "  Batch   300  of    996.    Elapsed: 0:00:21.\n",
      "  Batch   400  of    996.    Elapsed: 0:00:28.\n",
      "  Batch   500  of    996.    Elapsed: 0:00:34.\n",
      "  Batch   600  of    996.    Elapsed: 0:00:41.\n",
      "  Batch   700  of    996.    Elapsed: 0:00:48.\n",
      "  Batch   800  of    996.    Elapsed: 0:00:55.\n",
      "  Batch   900  of    996.    Elapsed: 0:01:02.\n",
      "\n",
      "Accuracy: 0.9405\n",
      "Test took: 0:01:09\n"
     ]
    }
   ],
   "source": [
    "#시작 시간 설정\n",
    "t0 = time.time()\n",
    "\n",
    "# 평가모드로 변경\n",
    "model.eval()\n",
    "\n",
    "# 변수 초기화\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    # 경과 정보 표시\n",
    "    if step % 100 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
    "\n",
    "    # 배치를 GPU에 넣음\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # 배치에서 데이터 추출\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "print(\"\")\n",
    "print(\"Accuracy: {0:.4f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "241502a7-1c5b-4b11-9f4f-8810762dbdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터 변환\n",
    "def convert_input_data(sentences):\n",
    "\n",
    "    # BERT의 토크나이저로 문장을 토큰으로 분리\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "    # 입력 토큰의 최대 시퀀스 길이\n",
    "    MAX_LEN = 128\n",
    "\n",
    "    # 토큰을 숫자 인덱스로 변환\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "    \n",
    "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    # 어텐션 마스크 초기화\n",
    "    attention_masks = []\n",
    "\n",
    "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "\n",
    "    # 데이터를 파이토치의 텐서로 변환\n",
    "    inputs = torch.tensor(input_ids)\n",
    "    masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return inputs, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79ceba6b-f965-4a45-9994-5dad3edbd969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 문장 테스트\n",
    "def test_sentences(sentences):\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 문장을 입력 데이터로 변환\n",
    "    inputs, masks = convert_input_data(sentences)\n",
    "\n",
    "    # 데이터를 GPU에 넣음\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_input_mask = masks.to(device)\n",
    "            \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d6dea38-a008-42fa-a1fa-660f78a2fcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "부정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "부정\n",
      "부정\n",
      "부정\n",
      "부정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "부정\n",
      "부정\n",
      "긍정\n",
      "긍정\n",
      "부정\n"
     ]
    }
   ],
   "source": [
    "sentences = pd.read_csv('./(final_final)review_test_data_total.csv', encoding = 'utf-8')\n",
    "sentences_re = []\n",
    "for i in sentences['review']:\n",
    "    # print(i)\n",
    "    # print('---------------------')\n",
    "    logits = test_sentences([i])\n",
    "    # print(logits)\n",
    "\n",
    "    if np.argmax(logits) == 1 :\n",
    "        print(\"긍정\")\n",
    "        sentences_re.append(1)\n",
    "    elif np.argmax(logits) == 0 :\n",
    "        print(\"부정\")\n",
    "        sentences_re.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d95b8cac-fc71-45f9-a666-f197b7ab011c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "541bb845-ec9c-481d-bf72-5d6b8ea564cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT 예측 확률 : 0.75\n"
     ]
    }
   ],
   "source": [
    "# 모델 예측값 Series화\n",
    "pd.Series(sentences_re)\n",
    "\n",
    "# gru_predict 컬럼 생성\n",
    "sentences['BERT_predict'] = pd.Series(sentences_re)\n",
    "\n",
    "# 일치도 확인\n",
    "sentences.loc[sentences['긍(1)/부정(0)'] == sentences['BERT_predict']]\n",
    "\n",
    "# 정확도 출력\n",
    "print('BERT 예측 확률 : {}'.format(len(sentences.loc[sentences['긍(1)/부정(0)'] == sentences['BERT_predict']])/len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e898ce09-5161-4180-9be2-980ddc50f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits = test_sentences([])\n",
    "# print(logits)\n",
    "\n",
    "# if np.argmax(logits) == 0 :\n",
    "#     print(\"부정\")\n",
    "    \n",
    "# elif np.argmax(logits) == 1 :\n",
    "#     print(\"긍정\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f06e6c1-9834-45d4-8d56-12d78e509249",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.read_csv('./(final)review_test_data_total.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7b601ca4-195e-4c17-b09a-eeed006980b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.argmax(test_sentences('안녕하세요'))\n",
    "np.argmax(test_sentences('안녕'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91b14a5-96c3-4eeb-88a2-6ee5634cb25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_re = []\n",
    "for i in sentences['review']:\n",
    "    logits = test_sentences([(i)])\n",
    "    if np.argmax(logits) == 0 :\n",
    "        sentences_re.append(0)\n",
    "    elif np.argmax(logits) == 1 :\n",
    "        sentences_re.append(1)\n",
    "    # test_sentences(i)\n",
    "    n += 1\n",
    "    print (logits)\n",
    "    # 긍부정 결과 리스트에 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "08197e99-3a5a-4ccd-9413-c289a588d0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.argmax(test_sentences('BERT야 왜그러니'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7ee46552-2f89-4997-a2cf-690b0ccd0a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "---------------------------------------------------------------\n",
      "이것저것 많이 올려놓을 수 있어서 좋고 내장된 콘센트도 좋아요 수납도 총 5칸 있어서 편해요 근데 예전 수납 침대에는 매트리스 아래 넓은 부분에 캐리어를 넣어놨는데 요 프레임은 높이(깊이)가 낮아서 캐리어 넣고 안 닫히더라구요 그점이 좀 아쉽지만 만족합니다 배송도 제가 원하는 날짜에 맞춰주셨고 기사님도 친절하고 좋았어요\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [91]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---------------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtest_sentences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m------------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m n \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Input \u001b[0;32mIn [90]\u001b[0m, in \u001b[0;36mtest_sentences\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m     17\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(b_input_ids, \n\u001b[1;32m     18\u001b[0m                     token_type_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[1;32m     19\u001b[0m                     attention_mask\u001b[38;5;241m=\u001b[39mb_input_mask)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 로스 구함\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# CPU로 데이터 이동\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# logits = logits.detach().cpu().numpy()\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "#파일 불러오기\n",
    "sentences = pd.read_csv('./(final)review_test_data_total.csv', encoding = 'utf-8')\n",
    "\n",
    "# 리뷰데이터 하나씩 불러와서 확인하기\n",
    "n = 1\n",
    "\n",
    "sentences_re = []\n",
    "for i in sentences['review']:\n",
    "    print(n)\n",
    "    print('---------------------------------------------------------------')\n",
    "    print(i)\n",
    "    print(test_sentences(i))\n",
    "    print('------------------------------------------------------------')\n",
    "    n += 1\n",
    "    # 긍부정 결과 리스트에 추가하기\n",
    "    # sentences_re.append(test_sentences(i))\n",
    "\n",
    "    logits = test_sentences(i)\n",
    "    if np.argmax(logits) == 0 :\n",
    "        sentences_re.append(0)\n",
    "    elif np.argmax(logits) == 1 :\n",
    "        sentences_re.append(1)\n",
    "    # # test_sentences(i)\n",
    "    n += 1\n",
    "    # print (sentences_re)\n",
    "\n",
    "\n",
    "# 모델 예측값 Series화\n",
    "pd.Series(sentences_re)\n",
    "\n",
    "# gru_predict 컬럼 생성\n",
    "sentences['BERT_predict'] = pd.Series(sentences_re)\n",
    "\n",
    "# 일치도 확인\n",
    "sentences.loc[sentences['긍(1)/부정(0)'] == sentences['BERT_predict']]\n",
    "\n",
    "# 정확도 출력\n",
    "print('BERT 예측 확률 : {}'.format(len(sentences.loc[sentences['긍(1)/부정(0)'] == sentences['BERT_predict']])/len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49eddaa7-0b4f-471c-a14c-4232b09d18f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20e45efd-64cb-4a6b-af41-9fd46f08d041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 5.5642, -5.6210]], device='cuda:0'), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e860c0-4d9e-4b90-a6bd-61f88ca1ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38",
   "language": "python",
   "name": "conda-env-azureml_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
